{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd17df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a seperate environment anr do <pip install llama-index>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bac7698-29a6-41f3-a05d-e8c4c6c4b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import AzureOpenAI\n",
    "from llama_index.embeddings import AzureOpenAIEmbedding\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout, level=logging.INFO\n",
    ")  # logging.DEBUG for more verbose output\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e5c1318-f3df-4c7a-82f0-c20a4410112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"xxxxxx\" # Replace with your key\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"xxxxxxx\" # replace with your base url\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\") # your endpoint should look like the following https://YOUR_RESOURCE_NAME.openai.azure.com/\n",
    "openai.api_type = 'azure'\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "\n",
    "deployment_name=\"xxxxxx\" # GPT Model deployment name\n",
    "deployment_embedding=\"xxxxxx\" # Embedding Model deployment name\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    model=\"gpt-35-turbo-16k\", # Change name to model being used\n",
    "    deployment_name=deployment_name,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"OPENAI_API_BASE\"),\n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    ")\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\", # Change name to model being used\n",
    "    deployment_name=deployment_embedding,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"OPENAI_API_BASE\"),\n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87834a6e-b486-47f1-888b-504b11cc4fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This code will set the basic configuration of the service\n",
    "\n",
    "from llama_index import set_global_service_context\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm=llm,embed_model=embed_model)\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f1b7cc5-1de9-47f7-847a-e3c56cbd87bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://madas-health-azureopenai.openai.azure.com//openai/deployments/embeddings-model/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://madas-health-azureopenai.openai.azure.com//openai/deployments/embeddings-model/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://madas-health-azureopenai.openai.azure.com//openai/deployments/embeddings-model/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://madas-health-azureopenai.openai.azure.com//openai/deployments/embeddings-model/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://madas-health-azureopenai.openai.azure.com//openai/deployments/embeddings-model/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://madas-health-azureopenai.openai.azure.com//openai/deployments/embeddings-model/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "#### Here we create embedding from data available to us\n",
    "\n",
    "documents = SimpleDirectoryReader(input_files=[\"./data/paul_graham_essay.txt\"]).load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50dd5eb1-aead-4844-a8fe-5e92eff247bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://madas-health-azureopenai.openai.azure.com//openai/deployments/embeddings-model/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://madas-health-azureopenai.openai.azure.com//openai/deployments/embeddings-model/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://madas-health-azureopenai.openai.azure.com//openai/deployments/madas-health-apis/chat/completions?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://madas-health-azureopenai.openai.azure.com//openai/deployments/madas-health-apis/chat/completions?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "### we can now perform retrieval agumented generation (RAG)\n",
    "\n",
    "query = \"What is most interesting about this essay?\"\n",
    "query_engine = index.as_query_engine()\n",
    "answer = query_engine.query(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9f61804-e81d-417b-9494-ee2fea7a40c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Source (Doc id: dcebc201-38a6-40d7-89dd-fcbe49e1628b): Notes\n",
      "\n",
      "[1] My experience skipped a step in the evolution of computers: time-sharing machines with...\n",
      "\n",
      "> Source (Doc id: 780bc1db-0c3f-4274-98ad-a0297cfd7f9d): A lot of Lisp hackers dream of building a new Lisp, partly because one of the distinctive feature...\n"
     ]
    }
   ],
   "source": [
    "# gets source of the answer\n",
    "print(answer.get_formatted_sources())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf5579f3-2b2f-4f3e-a9f6-696cd3a2cfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query was: What is most interesting about this essay?\n",
      "\n",
      "answer was: The most interesting aspect of this essay is the author's realization of the power of publishing essays online. The author describes how, in the print era, there was a limited channel for publishing essays, and only a select few were allowed to publish. However, with the advent of the internet, anyone could publish their essays online and reach a wide audience. This realization led the author to start publishing essays online and ultimately shaped their career. The author also reflects on the initial lack of prestige associated with online essays but finds encouragement in working on things that are not considered prestigious. This exploration of the changing landscape of publishing and the author's personal journey in embracing online essays makes for an intriguing read.\n"
     ]
    }
   ],
   "source": [
    "print(\"query was:\", query)\n",
    "print()\n",
    "print(\"answer was:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed4fa3-b80a-42e6-af00-1378e57012c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
